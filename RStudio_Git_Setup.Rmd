---
title: "Git_Setup"
output: html_document
date: "2025-10-20"
---


```{r 3_without_psidR}

library(tidyverse)
library(readr)
install.packages('arrow')
library(arrow)
install.packages('glue')
library(glue)
install.packages('stringr')
library(stringr)
install.packages('fs')
library(fs)
install.packages('here')
library(here)
```

```{r skeleton2} 
suppressPackageStartupMessages({
  library(readr); library(dplyr); library(stringr); library(tibble)
  library(purrr); library(fs);    library(glue);    library(here)
  library(arrow)
})

# ---- paths ----
DATA_DIR  <- here("data_raw")
XWALK_DIR <- here("xwalk")
OUT_PATH  <- here("output", "psid_family_year_2001_latest.parquet")

dir_create(DATA_DIR); dir_create(XWALK_DIR); dir_create(path_dir(OUT_PATH))

# If you only want specific waves, set here; otherwise weâ€™ll auto-detect
waves <- c(2001, 2003)

`%OR%` <- function(x, y) if (is.null(x) || length(x) == 0 || all(is.na(x))) y else x

parse_sps_positions <- function(dict_path) {
  lines <- read_lines(dict_path)
  dl_start <- which(str_detect(lines, regex("^\\s*DATA\\s+LIST", ignore_case = TRUE)))
  if (!length(dl_start)) return(tibble(var=character(), start=integer(), end=integer(), width=integer(), type=character()))
  after <- lines[seq(dl_start[1], length(lines))]
  stop_idx <- which(str_detect(after, regex("^\\s*VARIABLE\\s+LABELS", ignore_case = TRUE)))
  if (length(stop_idx)) after <- after[seq(1, stop_idx[1] - 1)]
  after <- gsub("\\t", " ", after)
  after <- gsub("\\*.*$", "", after)
  after <- str_squish(after)
  after <- after[after != ""]
  sl <- which(str_detect(after, "^/"))
  if (length(sl)) after <- after[seq(sl[1], length(after))]

  blob <- paste(after, collapse = " ")
  m <- str_match_all(blob, "(?i)\\b([A-Za-z0-9_]+)\\s+(\\d+)\\s*-\\s*(\\d+)\\s*(\\([aA]\\))?")[[1]]
  if (!nrow(m)) return(tibble(var=character(), start=integer(), end=integer(), width=integer(), type=character()))
  tibble(
    var   = m[,2],
    start = as.integer(m[,3]),
    end   = as.integer(m[,4]),
    type  = ifelse(!is.na(m[,5]) & m[,5] != "", "character", "numeric")
  ) |>
    mutate(width = end - start + 1L) |>
    distinct(var, .keep_all = TRUE) |>
    arrange(start)
}

parse_do_positions <- function(dict_path) {
  lines <- read_lines(dict_path) |> str_squish()
  pat <- "(str\\d+|byte|int|long|double)?\\s*([A-Za-z0-9_]+)\\s+(\\d+)\\s*-\\s*(\\d+)"
  toks <- str_extract_all(lines, pat) |> unlist()
  if (!length(toks)) return(tibble(var=character(), start=integer(), end=integer(), width=integer(), type=character()))
  mats <- str_match_all(toks, pat)
  map_dfr(mats, ~tibble(
    type_token = .x[,2],
    var        = .x[,3],
    start      = as.integer(.x[,4]),
    end        = as.integer(.x[,5])
  )) |>
    mutate(width = end - start + 1L,
           type  = ifelse(!is.na(type_token) & str_detect(type_token, "^str\\d+$"), "character", "numeric")) |>
    select(var, start, end, width, type) |>
    distinct(var, .keep_all = TRUE) |>
    arrange(start)
}

get_dict_positions <- function(stem) {
  sps <- path(DATA_DIR, paste0(stem, ".sps"))
  dof <- path(DATA_DIR, paste0(stem, ".do"))
  if (file_exists(sps)) return(parse_sps_positions(sps))
  if (file_exists(dof)) return(parse_do_positions(dof))
  warning(glue("No .sps or .do dictionary found for {stem}")); 
  tibble(var=character(), start=integer(), end=integer(), width=integer(), type=character())
}

read_fixed_width <- function(stem) {
  txt <- path(DATA_DIR, paste0(stem, ".txt"))
  if (!file_exists(txt)) {
    warning(glue("Missing {path_file(txt)}")); 
    return(tibble())
  }
  dict <- get_dict_positions(stem)
  if (!nrow(dict)) {
    warning(glue("No positions parsed from dictionary for {stem}")); 
    return(tibble())
  }
  fwf <- readr::fwf_positions(dict$start, dict$end, dict$var)
  col_types <- paste(ifelse(dict$type == "character", "c", "d"), collapse = "")
  df <- readr::read_fwf(file = txt, col_positions = fwf, col_types = col_types, na = c("", " ", ".", "NA"))
  char_cols <- names(df)[map_lgl(df, is.character)]
  df |> mutate(across(all_of(char_cols), ~na_if(str_trim(.x), "")))
}

safe_read_xwalk <- function(fname) {
  p <- path(XWALK_DIR, fname)
  if (!file_exists(p)) return(tibble(wave=integer(), varname=character(), source=character()))
  out <- tryCatch(
    readr::read_csv(p, show_col_types = FALSE),
    error = function(e) tibble(wave=integer(), varname=character(), source=character())
  )
  names(out) <- tolower(trimws(names(out)))
  needed <- c("wave","varname","source")
  if (!all(needed %in% names(out))) return(tibble(wave=integer(), varname=character(), source=character()))
  mutate(out, wave = as.integer(wave))
}

family_xw <- safe_read_xwalk("family_vars_crosswalk.csv")
hs_xw     <- safe_read_xwalk("head_spouse_crosswalk.csv")
indocc_xw <- safe_read_xwalk("industry_occupation_xwalk.csv")
phil_xw   <- safe_read_xwalk("philanthropy_crosswalk.csv")
mob_xw    <- safe_read_xwalk("mobility_crosswalk.csv")
state_xw  <- safe_read_xwalk("state_crosswalk.csv")
roster_xw <- safe_read_xwalk("roster_crosswalk.csv")

apply_xwalk <- function(df, xw, yr) {
  if (!nrow(df) || !nrow(xw)) return(tibble())
  xwy <- xw |> filter(wave == yr)
  if (!nrow(xwy)) return(tibble())
  keep <- intersect(xwy$source, names(df))
  if (!length(keep)) return(tibble())
  out <- select(df, all_of(keep))
  names(out) <- xwy |> filter(source %in% keep) |> arrange(match(source, keep)) |> pull(varname)
  out
}

# Remove duplicate-named columns, keeping the first
dedup_cols <- function(df) {
  if (anyDuplicated(names(df))) df <- df[, !duplicated(names(df)), drop = FALSE]
  df
}

load_family_wave <- function(yr) read_fixed_width(glue("FAM{yr}ER")) |> mutate(wave = yr)
load_indiv_wave  <- function(yr) {
  stems <- c(glue("IND{yr}ER"), glue("PR{yr}ER"))
  pick  <- stems[file_exists(path(DATA_DIR, paste0(stems, ".txt")))]
  if (!length(pick)) return(NULL)
  read_fixed_width(pick[[1]]) |> mutate(wave = yr)
}

find_family_id_col <- function(fam_df, yr) {
  src <- family_xw |> filter(wave == yr, varname == "family_id") |> pull(source) |> first()
  if (!is.na(src) && src %in% names(fam_df)) return(src)

  cands <- grep("^ER\\d{4,6}02$", names(fam_df), value = TRUE)
  if (length(cands)) {
    score <- vapply(cands, function(v){
      x <- suppressWarnings(as.numeric(fam_df[[v]]))
      n <- length(x); u <- length(unique(x))
      ok_num <- mean(!is.na(x)); ok_pos <- mean(x > 0, na.rm = TRUE)
      u / n + 0.5*ok_num + 0.25*ok_pos
    }, numeric(1))
    return(cands[which.max(score)])
  }

  if ("ER30002" %in% names(fam_df)) return("ER30002")
  stop("Could not identify family ID column for wave ", yr,
       ". Add a row to family_vars_crosswalk.csv: wave,varname,source => ",
       yr, ",family_id,ERxxxxx")
}

find_interview_year <- function(fam_df, yr) {
  src <- family_xw |> filter(wave == yr, varname == "interview_year") |> pull(source) |> first()
  if (!is.na(src) && src %in% names(fam_df)) return(suppressWarnings(as.integer(fam_df[[src]])))
  if ("ER30000" %in% names(fam_df)) return(suppressWarnings(as.integer(fam_df[["ER30000"]])))
  rep.int(as.integer(yr), nrow(fam_df))
}

build_wave <- function(yr) {
  fam <- load_family_wave(yr)
  if (!nrow(fam)) return(tibble())
  ind <- load_indiv_wave(yr)

  fam_id_col <- find_family_id_col(fam, yr)
  keys <- tibble(
    family_id      = fam[[fam_id_col]],
    interview_year = find_interview_year(fam, yr),
    wave           = as.integer(yr)
  )

  # prevent re-adding keys from the family crosswalk
  fam_xw_no_keys <- family_xw |> filter(!(varname %in% c("family_id","interview_year","wave")))

  add <- function(base, piece) if (!is.null(piece) && ncol(piece) > 0) bind_cols(base, piece) else base

  out <- keys |>
    add(apply_xwalk(fam, fam_xw_no_keys, yr)) |>
    add(apply_xwalk(fam, hs_xw,     yr)) |>
    add(apply_xwalk(fam, indocc_xw, yr)) |>
    add(apply_xwalk(fam, phil_xw,   yr)) |>
    add(apply_xwalk(fam, mob_xw,    yr)) |>
    add(apply_xwalk(fam, state_xw,  yr))

  # Optional: children < 18 (only if roster_xw + IND/PR are available)
  if (!is.null(ind) && nrow(roster_xw) && any(roster_xw$wave == yr)) {
    rxy <- roster_xw |> filter(wave == yr)
    age  <- rxy |> filter(varname=="age") |> pull(source)  |> first()
    in_fu<- rxy |> filter(varname=="in_fu") |> pull(source) |> first()
    rel  <- rxy |> filter(varname=="rel_to_head") |> pull(source) |> first()
    if (!any(is.na(c(age,in_fu,rel))) && all(c(age,in_fu,rel) %in% names(ind))) {
      IND_FID <- if ("ER30002" %in% names(ind)) "ER30002" else fam_id_col
      kids <- ind |>
        transmute(family_id = .data[[IND_FID]],
                  age = suppressWarnings(as.numeric(.data[[age]])),
                  in_fu = .data[[in_fu]]) |>
        mutate(in_fu_ok = if (is.numeric(in_fu)) in_fu == 1 else in_fu %in% c("1","Y","YES")) |>
        filter(in_fu_ok, !is.na(age), age < 18) |>
        count(family_id, name = "n_children_u18")
      out <- out |> left_join(kids, by = "family_id")
    }
  }

  if (!"n_children_u18" %in% names(out)) out <- mutate(out, n_children_u18 = 0L)
  dedup_cols(out)
}

fam_txts    <- dir_ls(DATA_DIR, regexp = "(?i)FAM\\d{4}ER\\.txt$")
found_years <- str_extract(path_file(fam_txts), "\\d{4}") |> as.integer()
use_years   <- (waves %OR% found_years) |> intersect(found_years) |> sort()
if (!length(use_years)) stop("No FAM####ER.txt files found in ", DATA_DIR)

panel <- map_dfr(use_years, build_wave)

# Normalize/guarantee keys
if (!"family_id" %in% names(panel)) stop("Build returned no family_id. Check crosswalk for family_id or heuristics.")
if (!"wave" %in% names(panel))      panel <- mutate(panel, wave = as.integer(NA))
if (!"interview_year" %in% names(panel)) panel <- mutate(panel, interview_year = wave)

panel <- panel |>
  mutate(interview_year = coalesce(interview_year, wave)) |>
  filter(!is.na(family_id), !is.na(wave), wave >= 2001) |>
  arrange(family_id, interview_year) |>
  relocate(family_id, interview_year, wave)

write_parquet(panel, OUT_PATH)
message("Skeleton written: ", OUT_PATH, 
        "  | rows=", nrow(panel), "  cols=", ncol(panel),
        "  | waves=", paste(unique(panel$wave), collapse=", "))
```

```{r check-numbers}
library(dplyr)

# 1) Confirm key uniqueness
panel %>% 
  count(family_id, interview_year, name = "n") %>% 
  filter(n > 1)
# -> should return 0 rows

# 2) How many families per wave?
panel %>% count(wave)

# 3) Any missing keys?
panel %>% summarise(
  n = n(),
  n_missing_family = sum(is.na(family_id)),
  n_missing_year   = sum(is.na(interview_year))
)

# 4) Look for obvious outliers (ages)
panel %>%
  summarise(
    min_head_age   = min(head_age,   na.rm = TRUE),
    max_head_age   = max(head_age,   na.rm = TRUE),
    min_spouse_age = min(spouse_age, na.rm = TRUE),
    max_spouse_age = max(spouse_age, na.rm = TRUE)
)

# 5) Verify each family has at most one row per wave
panel %>%
  count(family_id, wave) %>%
  filter(n > 1)

```
